<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Memory management · Muscade.jl</title><meta name="title" content="Memory management · Muscade.jl"/><meta property="og:title" content="Memory management · Muscade.jl"/><meta property="twitter:title" content="Memory management · Muscade.jl"/><meta name="description" content="Documentation for Muscade.jl."/><meta property="og:description" content="Documentation for Muscade.jl."/><meta property="twitter:description" content="Documentation for Muscade.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img src="assets/logo.png" alt="Muscade.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Introduction</a></li><li><a class="tocitem" href="Theory.html">Theory</a></li><li><span class="tocitem">User manual</span><ul><li><a class="tocitem" href="Modelling.html">Creating a model</a></li><li><a class="tocitem" href="Solvers.html">Solvers</a></li><li><a class="tocitem" href="Elements.html">Implementing new elements</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="StaticBeamAnalysis.html">Static analysis of a beam</a></li><li><a class="tocitem" href="DynamicBeamAnalysis.html">Modal analysis of a beam</a></li><li><a class="tocitem" href="DecayAnalysis.html">Estimating model parameters</a></li><li><a class="tocitem" href="DryFriction.html">DryFriction</a></li></ul></li><li><a class="tocitem" href="Diagnostic.html">Diagnostic</a></li><li><a class="tocitem" href="reference.html">Reference</a></li><li><span class="tocitem">Appendix</span><ul><li><a class="tocitem" href="TypeStable.html">Type-stability</a></li><li class="is-active"><a class="tocitem" href="Memory.html">Memory management</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#The-heap"><span>The heap</span></a></li><li><a class="tocitem" href="#The-stack"><span>The stack</span></a></li><li><a class="tocitem" href="#An-Array"><span>An <code>Array</code></span></a></li><li><a class="tocitem" href="#Strategies-for-performance"><span>Strategies for performance</span></a></li><li><a class="tocitem" href="#Procedural-strategy"><span>Procedural strategy</span></a></li><li><a class="tocitem" href="#Functional-strategy"><span>Functional strategy</span></a></li><li><a class="tocitem" href="#Working-with-immutables"><span>Working with immutables</span></a></li></ul></li><li><a class="tocitem" href="Adiff.html">Automatic differentiation</a></li><li><a class="tocitem" href="litterature.html">Literature</a></li></ul></li><li><a class="tocitem" href="LICENSE.html">MIT License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Appendix</a></li><li class="is-active"><a href="Memory.html">Memory management</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="Memory.html">Memory management</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SINTEF/Muscade.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SINTEF/Muscade.jl/blob/main/docs/src/Memory.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Memory-management"><a class="docs-heading-anchor" href="#Memory-management">Memory management</a><a id="Memory-management-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-management" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>Mutable structs, arguments passes by value to functions, garbage collection, variable names as tags. A variety of concept in Julia become easier to understand by considering how Julia manages memory, and how this affect performance.</p><p>In line with programming languages of the past decades, Julia uses two approaches to store variables, namely the <em>heap</em>, and the <em>stack</em>. Julia&#39;s designer made a few important choices on how they use heap and stack, and these strongly shape how we use the language, in particular when writing high-performance code.</p><h2 id="The-heap"><a class="docs-heading-anchor" href="#The-heap">The heap</a><a id="The-heap-1"></a><a class="docs-heading-anchor-permalink" href="#The-heap" title="Permalink"></a></h2><p>The heap is a swath of memory made available to a program.  When a variable is <em>allocated</em>, a preferably contiguous amount of available memory of the right size is found on the heap, and its adress (a pointer) is returned.  Values within that segment of memory can be written to or read, and the variable is <em>deallocated</em> when it is no longer in use.  </p><p>This is very flexible, but this flexibilty comes at a cost: To allocate a variable one must find available memory, thus there must be a heap-ledger describing what memory is available. Browsing the heap-ledger takes time.</p><p>Early in the execution of a program, the heap is unused, and finding space for new variables is easy.  But as variables are allocated and deallocated in arbitrary order, large contiguous area of free memory become rarer: the heap is fragmented, and there might be a need to swap things around (defragmentation).</p><p>Further, language designers must make a choice.  Option one is to let the programmer explicitely deallocate a variable when it is no longer needed.  Unfortunately, bugs in which a variable is not deallocate easily occur. If this happens in some loop, memory is allocated but not deallocated (a memory leak) and these bugs are nasty to track down.</p><p>The safer option 2, adopted by Julia, is to automaticaly deallocate memory on the heap when nothing anymore points to it.  That implies that there must be a pointer-ledger of all pointers into the heap, an the language must periodicaly go through the pointer-ledger to find orphaned heap-memory, update the heap-ledger, and possibly defragment the heap (move the variables in order to create large contiguous unallocated memory).  This process is called garbage collection.  While invisible to the programmer, the user sees it: it takes time.</p><p>When a profiler reports the number of allocations, it actualy refers to allocation on the heap, not counting variables created on the stack.</p><h2 id="The-stack"><a class="docs-heading-anchor" href="#The-stack">The stack</a><a id="The-stack-1"></a><a class="docs-heading-anchor-permalink" href="#The-stack" title="Permalink"></a></h2><p>The stack is a limited amount of memory managed on a &quot;last in first out&quot; basis: as a picture, the stack is vertical and when the stack start empty, the stack pointer points tot he base of the stack. If a new variable needs to be stored, it is added to the top of the stack and the pointer is updated. When the variable no longer needs to be stored, the pointer is just updated back to its previous value (pop the stack).</p><p>The mechanism for creating or destroying a variable is simple, and thus extremely fast.  The drawback of course is that variables are destroyed in reverse order of their creation, which is not always convenient.  However this works perfectly for: </p><ol><li>input arguments to a function, in languages where these are passed by values, and</li><li>local variables for the function.</li></ol><p>All these variables are created when entering the function, and destroyed when leaving it.  The (memory) stack thus fills as the code goes deeper into the call stack.  Recursions gone beserk typicaly result in a (memory) stack overflow.</p><p>That, at least, is how things looked like in the late pre-internet age.  Since then, CPUs have been equipped with a nested system of fast access caches. An outer cache, smaller and fast than RAM, a inner cache, yet smaller and faster, and the CPU&#39;s registers are, in a sense, the innermost caches.  It makes sense to store the data currently being processed into one of these inner caches.  But this comes at the cost of complexity to the language and compiler designers: <em>moving</em> data to the cache means to free its original location (which is awkward in the context of a stack). <em>Copying</em> data introduces the classic problem of keeping all copies of the data up to date.</p><p>Thus the designers of the Julia language made one important choice: <em>once a variable on the stack has been assigned a value, that value can never be changed</em>.  The variable is said to be <em>immutable</em>. This allows Julia copy any part of the stack to the CPU caches to optimize performance, without worrying about out-of-date copies. &quot;Immutables are easier to reason about&quot; says the doc: this may not be true when learning Julia, but applies when writing the compiler. </p><p>Now we see why variable names in Julia are best viualised as tags on a value (you copy the tag if you copy the value, and there can be multiple tags for the same value) as opposed to the parable of a variable as a box in which you can store different value (valid in other languages).</p><p>Julia&#39;s designers made another important choice: the size of all variables stored the stack must be known at compile time. This drasticaly simplifies the process of creating or destroying space on the stack when entering a function: just increment or decrement to stack pointer by a value determined for the function (actualy the method instance) at compile time.  Accessing a local variable from inside the function is likewise very fast: add a compile-time constant to the stack pointer, and that&#39;s were your data is.</p><p>As we will see, the fact that variables must be </p><ol><li>Immutable</li><li>Of size known at compile time</li></ol><p>significantly affects how one programs &quot;on the stack&quot; in Julia.</p><h2 id="An-Array"><a class="docs-heading-anchor" href="#An-Array">An <code>Array</code></a><a id="An-Array-1"></a><a class="docs-heading-anchor-permalink" href="#An-Array" title="Permalink"></a></h2><p>In Julia, an <code>Array{2,Float64}</code> is &quot;copied&quot;, for example by passing it as an argument to a function. What happens?</p><p>The array comes in several parts</p><ol><li>Heap-memory enough to store all the values in the array, in column major order. </li><li>A smaller amount of heap-memory containing.  a.  the sizes of the first and second indices of the array.  b.  a pointer to the storage 1. of the values.</li><li>On the stack, a pointer to 2.</li><li>Machine code that is written under the assumption that this array has two indices, that the size of an array element is 64 bits, that array elements can be copied directly to the CPU register for algebraic operations, etc.</li></ol><p>When the array is passed to a function, only 3., the pointer is actually passed to the function, as a copy placed at the right spot on the stack.  Being on the stack, the pointer is immutable: the function cannot reallocate 2. (as then the pointer to 2. would change value, pointing to a new spot on th heap). But one can change the content of the array, and its sizes (<code>push!</code>). Upon return from the function, the caller still has the pointer to a place on same spot on the heap: any change made by the function to values inside the array is visible by the caller.</p><p>If function overwrites the array as a whole however, the interpretation is different</p><pre><code class="language-julia hljs">function foo(a)
    a = [0,0]
end
A = [1,2]
foo(A)
@show A

2-element Vector{Int64}:
 1
 2</code></pre><p>Here <code>foo</code> was given a pointer to an array. By writing <code>a =</code>, <code>foo</code> discards its knowledge of the pointer, and uses the same tag-name to refer to a new spot of memory on the heap containing a pair of zeros.</p><h2 id="Strategies-for-performance"><a class="docs-heading-anchor" href="#Strategies-for-performance">Strategies for performance</a><a id="Strategies-for-performance-1"></a><a class="docs-heading-anchor-permalink" href="#Strategies-for-performance" title="Permalink"></a></h2><p>Allocating and deallocating memory on the heap takes time.  The amount of time for each allocation is tiny, but an ocean is just many drops. The time required is not proportional to the amount of memory allocated, but to the amount of individual allocations made.  So let us consider as an example a function inside of a hot loop, that needs internal memory for its local computations, and to return the results it produces.  For the function to be fast it must not allocate/deallocate memory on the heap. Two different strategies can be used to this effect, which we could call &quot;procedural&quot; and &quot;functional&quot;.</p><h2 id="Procedural-strategy"><a class="docs-heading-anchor" href="#Procedural-strategy">Procedural strategy</a><a id="Procedural-strategy-1"></a><a class="docs-heading-anchor-permalink" href="#Procedural-strategy" title="Permalink"></a></h2><p>In the procedural strategy, memory (say <code>Array</code>s) is preallocated &quot;once and for all&quot; on the heap, and passed to the function: arrays or slices of arrays are passed to the function.  The function uses this as work arrays and/or to return outputs: it is said to work &quot;in place&quot;.  In that way there is one (or several) allocation[s] before the hot loop, and many calls to the function.  In Julia, the naming convention for functions that thus modify their input arguments is to end the function name with <code>!</code>.</p><pre><code class="language-julia hljs">function double!(a)
    for i∈eachindex(a)
        a[i] *= 2
    end
end

a = randn(10)
for i = 1:10   # &quot;hot&quot; loop
    double!(a)
end</code></pre><p>This strategy is sometimes difficult to implement:</p><ol><li>If the function requires some working space, passing arrays to it is a breach of separation of concern (a new algorithm might require less, or more memory).</li><li>The return type of some functions might be hard to predict: even for type-stable functions, evaluating the types of an algorithm&#39;s output given the types of its inputs is sometimes best left to the compiler.</li><li>Algebraic operations, for example, are built into larger expression. In an implementation of <code>*</code>, to be used in <code>a*b+c</code>, operating in place is not an option (see however syntaxes like <code>d .= a.*b.+c</code> that <em>are</em> operating in place).</li></ol><h2 id="Functional-strategy"><a class="docs-heading-anchor" href="#Functional-strategy">Functional strategy</a><a id="Functional-strategy-1"></a><a class="docs-heading-anchor-permalink" href="#Functional-strategy" title="Permalink"></a></h2><p>In the functional strategy, the function creates new variables, both for intermediate results and for return value[s].  For performance, these variables are created on the stack, and must thus be immutable and of size known at compile time. </p><pre><code class="language-julia hljs">function double(a)
    b = 2 .*a
    return b
end

using StaticArrays
a = SVector{10}(randn() for i=1:10)
for i = 1:10   # &quot;hot&quot; loop
    a = double(a)
end</code></pre><p>Note that <code>double</code> is called with a <code>SVector</code>.  <code>SVector</code>s&#39; size is a parameter to the type, and is thus known at compile time. <code>SVector</code>s&#39; are immutable (<code>a[2] = 0</code> will throw an error), and thus <code>SVector</code>s live on the stack. If <code>double</code> was called with a <code>Vector</code> (which size is part of the value, and which is mutable), the operation <code>b = 2 .*a</code> would result in an allocation.</p><p>This strategy may also be difficult to implement:</p><ol><li>If many array sizes may be used (leading to the compilation of many method instances).</li><li>If array sizes depend on input <em>values</em>, using types in which size is part of the type leads to type-unstable code.</li><li>If large arrays are used, compile times will become excessively high.</li></ol><h2 id="Working-with-immutables"><a class="docs-heading-anchor" href="#Working-with-immutables">Working with immutables</a><a id="Working-with-immutables-1"></a><a class="docs-heading-anchor-permalink" href="#Working-with-immutables" title="Permalink"></a></h2><p><code>SArray</code>s, <code>ntuple</code>s and <code>NamedTuple</code>s are useful immutable datastructures.</p><p>If a for example an <code>SArray</code> can not be modified after it is created, how can we fill it with values?  Julia provides two syntaxs to do this, comprehensions and <code>do</code>-loops.  A comprehension looks like this:</p><pre><code class="language-julia hljs">using StaticArrays

const N=3 
f(i) = i^2

a = SVector{N}(f(i) for i=1:N)</code></pre><p>Importantly, <code>N</code> must be a compile-time constant.</p><p>A <code>do</code>-loop allows more complicated operations. We assume that the function <code>material</code> returns a <code>StaticArray</code> <code>σ</code> and a variable <code>χgp</code> of type difficult to predict. The <code>do</code>-loop creates the <code>ntuple</code> <code>accum</code>, which is then unpacked (using comprehensions) to sum the <code>σ</code> values into <code>r</code> and stack the <code>χgp</code> values into <code>χ</code>.</p><pre><code class="language-julia hljs">function residual(x,y)
    ngp   = 4
    accum = ntuple(ngp) do igp
        z = x[igp] + y[igp]
        σ, χgp = material(z)
        (σ=σ, χ=χgp) 
    end # do igp
    r = sum(        accum[igp].σ for igp=1:ngp)
    χ = NTuple{ngp}(accum[igp].χ for igp=1:ngp)
    return r,χ
end </code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="TypeStable.html">« Type-stability</a><a class="docs-footer-nextpage" href="Adiff.html">Automatic differentiation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.15.0 on <span class="colophon-date" title="Wednesday 29 October 2025 11:17">Wednesday 29 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
